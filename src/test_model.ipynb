{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import s3fs\n",
    "from typing import List, Optional, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import mlflow\n",
    "import pyarrow.parquet as pq\n",
    "import fasttext\n",
    "import os\n",
    "import warnings\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam, SGD\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "import unidecode\n",
    "# from src.model_negsamp import FastTextModule_negsamp, FastTextModel_negsamp\n",
    "from src.model import FastTextModule, FastTextModel\n",
    "from src.dataset import FastTextModelDataset\n",
    "from src.tokenizer import NGramTokenizer\n",
    "from src.preprocess import clean_text_feature\n",
    "import warnings\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 20\n",
    "vocab_size = 100\n",
    "num_classes=  35\n",
    "categorical_vocabulary_sizes = [5,7]\n",
    "padding_idx = 0\n",
    "sparse = True\n",
    "\n",
    "embeddings = nn.Embedding(\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_embeddings=vocab_size,\n",
    "    padding_idx=padding_idx,\n",
    "    sparse=sparse,\n",
    ")\n",
    "\n",
    "categorical_embeddings = {}\n",
    "\n",
    "for var_idx, vocab_size in enumerate(categorical_vocabulary_sizes):\n",
    "    emb = nn.Embedding(embedding_dim=embedding_dim, num_embeddings=vocab_size)\n",
    "    categorical_embeddings[var_idx] = emb\n",
    "    setattr(self, \"emb_{}\".format(var_idx), emb)\n",
    "\n",
    "self.fc = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, inputs: List[torch.LongTensor]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward method.\n",
    "\n",
    "        Args:\n",
    "            inputs (List[torch.LongTensor]): Model inputs.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Model output.\n",
    "        \"\"\"\n",
    "        # Embed tokens\n",
    "        x_1 = inputs[0]\n",
    "        x_1 = self.embeddings(x_1)\n",
    "\n",
    "        x_cat = []\n",
    "        for i, (variable, embedding_layer) in enumerate(\n",
    "            self.categorical_embeddings.items()\n",
    "        ):\n",
    "            x_cat.append(embedding_layer(inputs[i + 1]))\n",
    "\n",
    "        # Mean of tokens\n",
    "        non_zero_tokens = x_1.sum(-1) != 0\n",
    "        non_zero_tokens = non_zero_tokens.sum(-1)\n",
    "        x_1 = x_1.sum(dim=-2)\n",
    "        x_1 /= non_zero_tokens.unsqueeze(-1)\n",
    "        x_1 = torch.nan_to_num(x_1)\n",
    "\n",
    "        if x_cat != []:\n",
    "            x_in = x_1 + torch.stack(x_cat, dim=0).sum(dim=0)\n",
    "        else:\n",
    "            x_in = x_1\n",
    "\n",
    "        # Linear layer\n",
    "        z = self.fc(x_in)\n",
    "        return z\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
